{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15326e45-dd68-42c5-85f2-e328d9b4a1a7",
   "metadata": {},
   "source": [
    "# NETWORK ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120f56b-eb3b-40db-8a8a-ab21bcef90bb",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:16:04.149927Z",
     "start_time": "2025-01-14T18:16:04.076816Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from abc import ABC, abstractmethod\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, mean_absolute_error\n",
    "from collections import Counter, defaultdict\n",
    "import community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278d10f-05df-4fae-a0b2-57d8544c000b",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b26b9b1be9c687",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f428350a835a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:45:51.734412Z",
     "start_time": "2025-01-14T17:45:38.436746Z"
    }
   },
   "outputs": [],
   "source": [
    "caltech = nx.read_gml(r\"./fb100/data/Caltech36.gml\")\n",
    "jhopkins = nx.read_gml(r\"./fb100/data/Johns Hopkins55.gml\")\n",
    "mit = nx.read_gml(r\"./fb100/data/MIT8.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a49ef0a311b37b",
   "metadata": {},
   "source": [
    "#### Question 2.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93606251-3b80-4f6e-8d9a-425f1914d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [degree for _, degree in caltech.degree()]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(degrees, bins=range(min(degrees), max(degrees) + 2), align='left', rwidth=0.8)\n",
    "plt.title(\"Degree Distribution \\nCaltech\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(min(degrees), max(degrees) + 1), minor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d329b9e-1fcc-4b17-a8a9-c6a4c28a5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [degree for _, degree in mit.degree()]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(degrees, bins=range(min(degrees), max(degrees) + 2), align='left', rwidth=0.8)\n",
    "plt.title(\"Degree Distribution \\nMIT\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(min(degrees), max(degrees) + 1), minor=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab6a1e-c47e-43d3-b967-899e799be4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [degree for _, degree in jhopkins.degree()]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(degrees, bins=range(min(degrees), max(degrees) + 2), align='left', rwidth=0.8)\n",
    "plt.title(\"Degree Distribution \\nJohns Hopkins\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(min(degrees), max(degrees) + 1), minor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3135a425d7cf4",
   "metadata": {},
   "source": [
    "#### Question 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f250cbfe90f42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:03:42.272765Z",
     "start_time": "2025-01-14T18:03:18.013552Z"
    }
   },
   "outputs": [],
   "source": [
    "global_clustering_c = nx.transitivity(caltech)\n",
    "mean_local_clustering_c = nx.average_clustering(caltech)\n",
    "edge_density_c = nx.density(caltech)\n",
    "print(f\"Caltech :\")\n",
    "print(f\"- Global Clustering Coefficient: {global_clustering_c:.4f}\")\n",
    "print(f\"- Mean Local Clustering Coefficient: {mean_local_clustering_c:.4f}\")\n",
    "print(f\"- Edge Density: {edge_density_c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc8666-0bbb-42a1-8ac1-6b2be3f561ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_clustering_m = nx.transitivity(mit)\n",
    "mean_local_clustering_m = nx.average_clustering(mit)\n",
    "edge_density_m = nx.density(mit)\n",
    "print(f\"MIT :\")\n",
    "print(f\"- Global Clustering Coefficient: {global_clustering_m:.4f}-\")\n",
    "print(f\"- Mean Local Clustering Coefficient: {mean_local_clustering_m:.4f}\")\n",
    "print(f\"- Edge Density: {edge_density_m:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070658-234d-4f91-8bef-61d8b21099c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_clustering_j = nx.transitivity(jhopkins)\n",
    "mean_local_clustering_j = nx.average_clustering(jhopkins)\n",
    "edge_density_j = nx.density(jhopkins)\n",
    "print(f\"Johns Hopkins :\")\n",
    "print(f\"- Global Clustering Coefficient: {global_clustering_j:.4f}\")\n",
    "print(f\"- Mean Local Clustering Coefficient: {mean_local_clustering_j:.4f}\")\n",
    "print(f\"- Edge Density: {edge_density_j:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a7ee1db7f9363",
   "metadata": {},
   "source": [
    "#### Question 2.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e44d00fbe2a565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:10:26.984278Z",
     "start_time": "2025-01-14T18:10:15.375961Z"
    }
   },
   "outputs": [],
   "source": [
    "degrees = dict(caltech.degree())  \n",
    "local_clustering = nx.clustering(caltech)  \n",
    "x = list(degrees.values())  \n",
    "y = list(local_clustering.values()) \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(x, y, alpha=0.7)\n",
    "plt.title(\"Degree vs Local Clustering Coefficient \\nCaltech\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Local Clustering Coefficient\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb357c29-cb42-4e00-8257-10dee298e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(mit.degree())  \n",
    "local_clustering = nx.clustering(mit)  \n",
    "x = list(degrees.values())  \n",
    "y = list(local_clustering.values()) \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(x, y, alpha=0.7)\n",
    "plt.title(\"Degree vs Local Clustering Coefficient \\nMIT\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Local Clustering Coefficient\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab8551-fae3-4e31-b321-615d41b73180",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(jhopkins.degree())  \n",
    "local_clustering = nx.clustering(jhopkins)  \n",
    "x = list(degrees.values())  \n",
    "y = list(local_clustering.values()) \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(x, y, alpha=0.7)\n",
    "plt.title(\"Degree vs Local Clustering Coefficient \\nJohns Hopkins\", fontsize=16)\n",
    "plt.xlabel(\"Degree\", fontsize=14)\n",
    "plt.ylabel(\"Local Clustering Coefficient\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73976fa2-2315-43fa-a17d-c51f93c8acd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144a09178d84ea04",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e467ebae3fcb84d",
   "metadata": {},
   "source": [
    "#### Question 3.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2218e4f972236",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-14T18:24:43.817075Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = \"fb100/data\"\n",
    "attributes = [\"student_fac\", \"dorm\", \"gender\", \"major_index\"] \n",
    "results = {attr: {\"sizes\": [], \"assortativity\": []} for attr in attributes}\n",
    "results[\"degree\"] = {\"sizes\": [], \"assortativity\": []}\n",
    "\n",
    "files = [f for f in os.listdir(data) if f.endswith(\".gml\")]\n",
    "files = files[:50]\n",
    "\n",
    "for gml_file in tqdm(files, desc=\"Processing GML files\"):\n",
    "    graph_path = os.path.join(data, gml_file)\n",
    "    graph = nx.read_gml(graph_path)\n",
    "    n = len(graph)\n",
    "    for attr in attributes:\n",
    "        if nx.get_node_attributes(graph, attr): \n",
    "            assortativity = nx.attribute_assortativity_coefficient(graph, attr)\n",
    "            results[attr][\"sizes\"].append(n)\n",
    "            results[attr][\"assortativity\"].append(assortativity)\n",
    "    degree_assortativity = nx.degree_assortativity_coefficient(graph)\n",
    "    results[\"degree\"][\"sizes\"].append(n)\n",
    "    results[\"degree\"][\"assortativity\"].append(degree_assortativity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa01ab5886b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_and_distribution(results, attr):\n",
    "    sizes = results[attr][\"sizes\"]\n",
    "    assortativity = results[attr][\"assortativity\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    axes[0].scatter(sizes, assortativity, alpha=0.7)\n",
    "    axes[0].set_xscale(\"log\")\n",
    "    axes[0].axhline(0, linestyle=\"--\", color='r', label=\"No Assortativity\")\n",
    "    axes[0].set_title(f\"Assortativity vs Network Size ({attr.replace('_', ' ').capitalize()})\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"Network Size (n)\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Assortativity\", fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].hist(assortativity, bins=20, alpha=0.7)\n",
    "    axes[1].axvline(0, linestyle=\"--\", color='r', label=\"No Assortativity\")\n",
    "    axes[1].set_title(f\"Distribution of Assortativity ({attr.replace('_', ' ').capitalize()})\", fontsize=14)\n",
    "    axes[1].set_xlabel(\"Assortativity\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Frequency\", fontsize=12)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79910aa-c93d-4fed-a8c3-f49e3e02647d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attr in attributes + [\"degree\"]:\n",
    "    plot_scatter_and_distribution(results, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f6611-79af-4111-bf33-b1a676fc33a8",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23c247-4ee7-45ef-8927-d11169e3a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPrediction(ABC):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "    \n",
    "    def neighbors(self, v):\n",
    "        return set(self.graph.neighbors(v))\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, u, v):\n",
    "        pass\n",
    "\n",
    "class CommonNeighbors(LinkPrediction):\n",
    "    def predict(self, u, v):\n",
    "        return len(self.neighbors(u) & self.neighbors(v))\n",
    "\n",
    "class JaccardCoefficient(LinkPrediction):\n",
    "    def predict(self, u, v):\n",
    "        union_size = len(self.neighbors(u) | self.neighbors(v))\n",
    "        return len(self.neighbors(u) & self.neighbors(v)) / union_size if union_size > 0 else 0\n",
    "\n",
    "class AdamicAdar(LinkPrediction):\n",
    "    def predict(self, u, v):\n",
    "        return sum(1 / np.log(len(self.neighbors(w))) for w in self.neighbors(u) & self.neighbors(v) if len(self.neighbors(w)) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a73a37c-9543-4f93-9b7b-189befa7c653",
   "metadata": {},
   "source": [
    "#### Common Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48a03d-ddb0-46a9-8870-e4da3a3a8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, G in zip(['Caltech', 'Hopkins', 'MIT'],[caltech, jhopkins, mit]):\n",
    "    print(name)\n",
    "    for f in [0.05, 0.1, 0.15, 0.2]:\n",
    "        print(f\"percentage removed {f*100:.0f}%\")\n",
    "        edges = list(G.edges())\n",
    "        random.shuffle(edges)\n",
    "        removed_edges = edges[:int(f * len(edges))]\n",
    "        G.remove_edges_from(removed_edges)\n",
    "        \n",
    "        predictor = CommonNeighbors(G)\n",
    "        predictions = [(u, v, predictor.predict(u, v)) for u, v in removed_edges]\n",
    "        predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        k_values = [50, 100, 200, 400]\n",
    "        for k in k_values:\n",
    "            top_k_predictions = {e[:2] for e in predictions[:k]}\n",
    "            removed_set = set(removed_edges)\n",
    "            tp = len(top_k_predictions & removed_set)\n",
    "            precision = tp / k\n",
    "            recall = tp / len(removed_set)\n",
    "            print(f\"k={k}: Precision={precision:.4f}, Recall={recall:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7c607-c73e-4bb6-b6cd-b668032038cf",
   "metadata": {},
   "source": [
    "#### Jaccard Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e9a44-6b2b-439f-aa43-4884f825a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, G in zip(['Caltech', 'Hopkins', 'MIT'],[caltech, jhopkins, mit]):\n",
    "    print(name)\n",
    "    for f in [0.05, 0.1, 0.15, 0.2]:\n",
    "        print(f\"percentage removed {f*100:.0f}%\")\n",
    "        edges = list(G.edges())\n",
    "        random.shuffle(edges)\n",
    "        removed_edges = edges[:int(f * len(edges))]\n",
    "        G.remove_edges_from(removed_edges)\n",
    "        \n",
    "        predictor = JaccardCoefficient(G)\n",
    "        predictions = [(u, v, predictor.predict(u, v)) for u, v in removed_edges]\n",
    "        predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        k_values = [50, 100, 200, 400]\n",
    "        for k in k_values:\n",
    "            top_k_predictions = {e[:2] for e in predictions[:k]}\n",
    "            removed_set = set(removed_edges)\n",
    "            tp = len(top_k_predictions & removed_set)\n",
    "            precision = tp / k\n",
    "            recall = tp / len(removed_set)\n",
    "            print(f\"k={k}: Precision={precision:.4f}, Recall={recall:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616475ee-37aa-4c83-a4de-1f686a4f8d06",
   "metadata": {},
   "source": [
    "#### AdamicAdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8292c2d-2f4a-41c6-9818-ba9d9743c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, G in zip(['Caltech', 'Hopkins', 'MIT'],[caltech, jhopkins, mit]):\n",
    "    print(name)\n",
    "    for f in [0.05, 0.1, 0.15, 0.2]:\n",
    "        print(f\"percentage removed {f*100:.0f}%\")\n",
    "        edges = list(G.edges())\n",
    "        random.shuffle(edges)\n",
    "        removed_edges = edges[:int(f * len(edges))]\n",
    "        G.remove_edges_from(removed_edges)\n",
    "        \n",
    "        predictor = AdamicAdar(G)\n",
    "        predictions = [(u, v, predictor.predict(u, v)) for u, v in removed_edges]\n",
    "        predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        k_values = [50, 100, 200, 400]\n",
    "        for k in k_values:\n",
    "            top_k_predictions = {e[:2] for e in predictions[:k]}\n",
    "            removed_set = set(removed_edges)\n",
    "            tp = len(top_k_predictions & removed_set)\n",
    "            precision = tp / k\n",
    "            recall = tp / len(removed_set)\n",
    "            print(f\"k={k}: Precision={precision:.4f}, Recall={recall:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119babc3-3e46-4899-a510-48792ecf9011",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Question 5.A \n",
    "### Question 5.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fabf60-0dde-48d5-8011-fa68e6554296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPropagation:\n",
    "    def __init__(self, graph, attribute, max_iter=100):\n",
    "        self.graph = graph\n",
    "        self.attribute = attribute\n",
    "        self.max_iter = max_iter\n",
    "        self.labels = nx.get_node_attributes(graph, attribute)\n",
    "        self.missing_nodes = [node for node in graph.nodes() if node not in self.labels]\n",
    "\n",
    "    def propagate(self):\n",
    "        for _ in range(self.max_iter):\n",
    "            new_labels = self.labels.copy()\n",
    "            for node in self.missing_nodes:\n",
    "                neighbors = list(self.graph.neighbors(node))\n",
    "                if neighbors:\n",
    "                    neighbor_labels = [self.labels[neighbor] for neighbor in neighbors if neighbor in self.labels]\n",
    "                    if neighbor_labels:\n",
    "                        new_labels[node] = Counter(neighbor_labels).most_common(1)[0][0] \n",
    "            self.labels = new_labels\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "\n",
    "def evaluate_label_propagation(graph, attribute, fractions):\n",
    "    results = {fraction: {\"mae\": [], \"accuracy\": []} for fraction in fractions}\n",
    "    \n",
    "    for fraction in tqdm(fractions, desc=\"Evaluating fractions\"):\n",
    "        for _ in range(10):  # Run multiple iterations for averaging\n",
    "            graph_copy = graph.copy()\n",
    "            labels = nx.get_node_attributes(graph_copy, attribute)\n",
    "            \n",
    "            all_nodes = list(graph_copy.nodes())\n",
    "            num_to_remove = int(fraction * len(all_nodes))\n",
    "            if num_to_remove == 0:\n",
    "                continue  \n",
    "            \n",
    "            missing_nodes = np.random.choice(all_nodes, num_to_remove, replace=False)\n",
    "            \n",
    "            for node in missing_nodes:\n",
    "                labels.pop(node, None)\n",
    "            nx.set_node_attributes(graph_copy, labels, attribute)\n",
    "            \n",
    "            lp = LabelPropagation(graph_copy, attribute)\n",
    "            lp.propagate()\n",
    "            recovered_labels = lp.get_labels()\n",
    "\n",
    "            true_labels = nx.get_node_attributes(graph, attribute)\n",
    "            predicted_labels = {node: recovered_labels.get(node, None) for node in missing_nodes if node in recovered_labels}\n",
    "            true_labels = {node: true_labels[node] for node in missing_nodes if node in true_labels}\n",
    "            \n",
    "            if not true_labels or not predicted_labels:\n",
    "                continue\n",
    "\n",
    "            accuracy = accuracy_score(list(true_labels.values()), list(predicted_labels.values()))\n",
    "            mae = mean_absolute_error(list(true_labels.values()), list(predicted_labels.values()))\n",
    "\n",
    "            results[fraction][\"accuracy\"].append(accuracy)\n",
    "            results[fraction][\"mae\"].append(mae)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f3b8d-3976-4cc3-9d62-51e91be40e92",
   "metadata": {},
   "source": [
    "### Question 5.C and 5.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b68a74-0b56-4564-bb56-81bcf5a2dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"dorm\", \"major_index\", \"gender\"]\n",
    "fractions = [0.1, 0.2, 0.3]\n",
    "\n",
    "files = [f for f in os.listdir(data) if f.endswith(\".gml\")][:10]\n",
    "\n",
    "for gml_file in tqdm(files, desc=\"Processing GML files\"):\n",
    "    graph_path = os.path.join(data, gml_file)\n",
    "    graph = nx.read_gml(graph_path)\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        if nx.get_node_attributes(graph, attribute):  \n",
    "            results = evaluate_label_propagation(graph, attribute, fractions)\n",
    "            print(f\"Results for {gml_file} - {attribute}:\")\n",
    "            \n",
    "            for fraction in fractions:\n",
    "                if results[fraction][\"accuracy\"]:  \n",
    "                    accuracy = np.mean(results[fraction][\"accuracy\"])\n",
    "                    mae = np.mean(results[fraction][\"mae\"])\n",
    "                    print(f\"  Fraction: {fraction} - Accuracy: {accuracy:.4f} - MAE: {mae:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  Fraction: {fraction} - No valid results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6128cd0-5912-4662-b39a-d774b1b0492c",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Question 6.A\n",
    "\n",
    "**Research Question:** \n",
    "\n",
    "Do students in the same academic major tend to form tighter communities within the Facebook100 dataset?\n",
    "\n",
    "**Hypothesis:** \n",
    "\n",
    "Students in the same academic major are more likely to form tightly-knit communities within the social network. This hypothesis is based on the idea that students sharing the same academic interests and courses are more likely to interact and form friendships, leading to denser and more cohesive communities within the network.\n",
    "\n",
    "Justification:\n",
    "Rationaly, we can expect that students in the same major often share classes, study groups, and academic interests, which can lead to more frequent interactions and stronger social ties.\n",
    "\n",
    "If the communities are predominantly composed of students from the same major, it would support our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d170519-f548-4a8c-b3d5-5c5582468259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_communities(graph, partition, attribute):\n",
    "    pos = nx.spring_layout(graph, seed=42, k=20 * (1 / np.sqrt(len(graph.nodes)))) \n",
    "    cmap = plt.get_cmap('tab10') \n",
    "    plt.figure(figsize=(16, 12)) \n",
    "\n",
    "    for community_id in set(partition.values()):\n",
    "        list_nodes = [node for node in partition.keys() if partition[node] == community_id]\n",
    "        nx.draw_networkx_nodes(\n",
    "            graph,\n",
    "            pos,\n",
    "            nodelist=list_nodes,\n",
    "            node_size=80,\n",
    "            node_color=[cmap(community_id % cmap.N)] * len(list_nodes),\n",
    "            label=f\"Community {community_id}\",\n",
    "            alpha=0.9,\n",
    "        )\n",
    "\n",
    "    nx.draw_networkx_edges(graph, pos, alpha=0.3, width=0.5)\n",
    "\n",
    "    plt.title(\"Community Visualization\", fontsize=18)\n",
    "    plt.legend(scatterpoints=1, loc=\"best\", fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def load_graph(file_path):\n",
    "    return nx.read_gml(file_path)\n",
    "\n",
    "def detect_communities(graph):\n",
    "    partition = community.best_partition(graph)\n",
    "    return partition\n",
    "\n",
    "def analyze_communities(graph, partition, attribute):\n",
    "    attribute_dict = nx.get_node_attributes(graph, attribute)\n",
    "    community_major_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for node, community_id in partition.items():\n",
    "        if node in attribute_dict:\n",
    "            major = attribute_dict[node]\n",
    "            community_major_counts[community_id][major] += 1\n",
    "\n",
    "    return community_major_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30beaa4b-83c6-4df0-81c5-940decfa4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_file = \"Caltech36.gml\" \n",
    "attribute = \"major_index\"  \n",
    "\n",
    "graph_path = os.path.join(data, network_file)\n",
    "graph = load_graph(graph_path)\n",
    "\n",
    "partition = detect_communities(graph)\n",
    "\n",
    "community_major_counts = analyze_communities(graph, partition, attribute)\n",
    "for community_id, major_counts in community_major_counts.items():\n",
    "    print(f\"Community {community_id}:\")\n",
    "    for major, count in major_counts.items():\n",
    "        print(f\"  Major {major}: {count} students\")\n",
    "\n",
    "plot_communities(graph, partition, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec425aa-9850-490c-804a-62da67ac6e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21964b1d-b3cd-4ee3-ac66-2e5e6cce86ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b2ad1-c4e4-4a9c-8876-0e844d31f2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302c6ae-1863-45e7-88ef-a36c0fb7d1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa5b13-9e72-4843-851f-fe157870f391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
